{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This work has been replicated from https://www.kaggle.com/code/priyankdl/sentiment-analysis-imdb-torchtext-gru"
      ],
      "metadata": {
        "id": "rOUhkwM9Uv4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing a few dependencies"
      ],
      "metadata": {
        "id": "DL1F0XSOyZAL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26zz8kQ8yYf8",
        "outputId": "e475388e-e4f5-49c4-e80f-a223f1124a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m539.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cpu\n",
            "    Uninstalling torch-2.5.0+cpu:\n",
            "      Successfully uninstalled torch-2.5.0+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cpu requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.0+cpu requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cmake-3.30.5 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2\n",
        "!pip install 'portalocker>=2.0.0'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all the dependencies"
      ],
      "metadata": {
        "id": "T0lY06iE0T2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchtext import datasets\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import numpy as np\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "U0zpxL1L0S4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting to know the training and testing datasets"
      ],
      "metadata": {
        "id": "v0EVdyRo0tn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_iterator=datasets.IMDB(split='train')\n",
        "test_dataset_iterator=datasets.IMDB(split='test')"
      ],
      "metadata": {
        "id": "cXT26oab0s0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=[]\n",
        "test_data=[]\n",
        "\n",
        "train_reviews=[]\n",
        "\n",
        "for label,review in train_dataset_iterator:\n",
        "  train_data.append([review,label])\n",
        "  train_reviews.append(review)\n",
        "\n",
        "for label,review in test_dataset_iterator:\n",
        "  test_data.append([review,label])\n",
        "\n",
        "print(\"Training_data_length:\",len(train_data))\n",
        "print(\"Testing_data_length:\",len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNkxLQNL0-Tg",
        "outputId": "2aefd0c7-a29d-4ecf-eb54-f46bb4b02ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training_data_length: 25000\n",
            "Testing_data_length: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=get_tokenizer(\"basic_english\",\"en\")\n",
        "vocab=build_vocab_from_iterator(\n",
        "    map(tokenizer,train_reviews),\n",
        "    specials=[\"<unk>\",\"<pad>\",\"<eos>\"],\n",
        "    special_first=True,\n",
        "    min_freq=5\n",
        ")\n",
        "\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "print(\"The Vocab Size is :\",vocab.__len__())\n",
        "\n",
        "def text_pipeline(review):\n",
        "  return vocab.lookup_indices(tokenizer(review))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnLk3lbW3HnG",
        "outputId": "e9efe444-e631-4602-d57a-87fc2f970abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Vocab Size is : 30124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file_path=\"vocab.txt\"\n",
        "with open (vocab_file_path,\"w\") as f:\n",
        "  for token, index in vocab.get_stoi().items():\n",
        "    f.write(f\"{token}\\t{index}\\n\")"
      ],
      "metadata": {
        "id": "ZfgvbJYUggoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colate_fn(batch,text_pipeline):\n",
        "  input=[]\n",
        "  ground_truth=[]\n",
        "  for data in batch:\n",
        "    review=data[0]\n",
        "    label=data[1]-1\n",
        "\n",
        "    numeric_tokens=text_pipeline(review)\n",
        "    if (len(numeric_tokens)>256):\n",
        "      numeric_tokens=numeric_tokens[:256]\n",
        "    while (len(numeric_tokens)<256):\n",
        "      numeric_tokens.append(0)\n",
        "    input.append(numeric_tokens)\n",
        "    ground_truth.append(label)\n",
        "\n",
        "  input=torch.tensor(input,dtype=torch.long)\n",
        "  ground_truth=torch.tensor(ground_truth,dtype=torch.long)\n",
        "\n",
        "  return input,ground_truth"
      ],
      "metadata": {
        "id": "nmdLLke-29we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the dataloaders onto the train and test data"
      ],
      "metadata": {
        "id": "AeFy9_WX7Gl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader=DataLoader(\n",
        "    train_data,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    collate_fn=partial(colate_fn,text_pipeline=text_pipeline)\n",
        ")\n",
        "\n",
        "test_dataloader=DataLoader(\n",
        "    test_data,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    collate_fn=partial(colate_fn,text_pipeline=text_pipeline)\n",
        ")"
      ],
      "metadata": {
        "id": "k20qEAeC7GBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the model"
      ],
      "metadata": {
        "id": "DnfQROVV7wjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAnalysis(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.em=nn.Embedding(vocab_size,128)\n",
        "    self.drop=nn.Dropout(0.2)\n",
        "    self.gru=nn.GRU(128,256,batch_first=True)\n",
        "    self.classifier=nn.Linear(256,2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.em(x)\n",
        "    x=self.drop(x)\n",
        "    outputs,hidden=self.gru(x)\n",
        "    hidden.squeeze_(0)\n",
        "    x=self.classifier(hidden)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "5uhu9XV77xwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train one epoch"
      ],
      "metadata": {
        "id": "vSjC-oFS90NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SAnalysis(vocab.__len__())\n",
        "\n",
        "optimiser=optim.Adam(model.parameters(),lr=0.001)\n",
        "loss_function=nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "puulAnYJ_MKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model,dataloader,optim,loss_function):\n",
        "  model.train()\n",
        "\n",
        "  running_loss=[]\n",
        "  running_acc=[]\n",
        "  track_loss=0\n",
        "  num_correct=0\n",
        "  i=0\n",
        "  for reviews,label in dataloader:\n",
        "    output=model(reviews)\n",
        "    loss=loss_function(output,label)\n",
        "\n",
        "    track_loss+=loss.item()\n",
        "    num_correct+=(torch.argmax(output,dim=1)==label).type(torch.float).sum().item()\n",
        "    running_loss=round(track_loss/(i+(reviews.shape[0]/16)),4)\n",
        "    running_acc=round((num_correct/((i*16+reviews.shape[0])))*100,4)\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  print(\"EVAL LOOP:LOSS \",running_loss)\n",
        "  print(\"EVAL LOOP:Accuracy \",running_acc)\n"
      ],
      "metadata": {
        "id": "_pwfqgFs918l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_one_epoch(model,dataloader,loss_function):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  running_loss=[]\n",
        "  running_acc=[]\n",
        "  track_loss=0\n",
        "  num_correct=0\n",
        "\n",
        "  i=0\n",
        "\n",
        "  for reviews,label in dataloader:\n",
        "    output=model(reviews)\n",
        "    loss=loss_function(output,label)\n",
        "\n",
        "    track_loss+=loss.item()\n",
        "    num_correct+=(torch.argmax(output,dim=1)==label).type(torch.float).sum().item()\n",
        "    running_loss=round(track_loss/(i+(reviews.shape[0]/16)),4)\n",
        "    running_acc=round((num_correct/((i*16+reviews.shape[0])))*100,4)\n",
        "\n",
        "    i+=1\n",
        "\n",
        "  print(\"EVAL LOOP:LOSS \",running_loss)\n",
        "  print(\"EVAL LOOP:Accuracy \",running_acc)"
      ],
      "metadata": {
        "id": "wBSsmLiLADLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=2\n",
        "for i in range(epochs):\n",
        "  train_one_epoch(model,train_dataloader,optimiser,loss_function)\n",
        "  eval_one_epoch(model,test_dataloader,loss_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDHttyNZAR2P",
        "outputId": "f69a45fc-659e-43e2-a3ba-0ddf68967fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVAL LOOP:LOSS  0.6791\n",
            "EVAL LOOP:Accuracy  54.544\n",
            "EVAL LOOP:LOSS  0.5219\n",
            "EVAL LOOP:Accuracy  75.492\n",
            "EVAL LOOP:LOSS  0.3735\n",
            "EVAL LOOP:Accuracy  83.612\n",
            "EVAL LOOP:LOSS  0.3137\n",
            "EVAL LOOP:Accuracy  86.288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,\"model.pth\")"
      ],
      "metadata": {
        "id": "B9XUoOTozuhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model_state_dict.pth\")"
      ],
      "metadata": {
        "id": "5ODBXCOe5ntu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}