{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyperspectral01/Natural_Language_Computing/blob/main/2.Introduction_to_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook has been created after referencing https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
      ],
      "metadata": {
        "id": "SFwg_cbRUKVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dependencies"
      ],
      "metadata": {
        "id": "QyI9oAQzNJcS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbYMel98NFGt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzVIquFMFh1N",
        "outputId": "fcd9adb5-9638-4a53-b499-019d0d51b364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mapping** the Output Classes to different Labels"
      ],
      "metadata": {
        "id": "Z0K4hw7dNU4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}"
      ],
      "metadata": {
        "id": "co9aDSZZNVd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the FashionMNIST data and looking at the shapes"
      ],
      "metadata": {
        "id": "6mZ64XgiNaF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, index=torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "sR5Y6mziNbAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10,dtype=torch.float).scatter_(dim=0,index=torch.tensor(y),value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "1tRpSvOlNiGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now looking at the shapes of the datasets"
      ],
      "metadata": {
        "id": "8hAYHt0hOgVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0TcIPm5Ojby",
        "outputId": "7d257497-3e41-4b2f-bc5e-2f1cb6174534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Target transform: Lambda()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0oM3IhLPZwh",
        "outputId": "1f86c2c5-5537-44f1-94ea-bdadf9e46418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "Target transform: Lambda()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUwewNPTPvkc",
        "outputId": "f329fc7c-207f-4004-e036-956d1372cdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
            "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0039, 0.0039, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
            "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
            "          0.0157, 0.0000, 0.0000, 0.0118],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
            "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0471, 0.0392, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
            "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
            "          0.3020, 0.5098, 0.2824, 0.0588],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
            "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
            "          0.5529, 0.3451, 0.6745, 0.2588],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
            "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
            "          0.4824, 0.7686, 0.8980, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
            "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
            "          0.8745, 0.9608, 0.6784, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
            "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
            "          0.8627, 0.9529, 0.7922, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
            "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
            "          0.8863, 0.7725, 0.8196, 0.2039],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
            "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
            "          0.9608, 0.4667, 0.6549, 0.2196],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
            "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
            "          0.8510, 0.8196, 0.3608, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
            "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
            "          0.8549, 1.0000, 0.3020, 0.0000],\n",
            "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
            "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
            "          0.8784, 0.9569, 0.6235, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
            "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
            "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
            "          0.9137, 0.9333, 0.8431, 0.0000],\n",
            "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
            "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
            "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
            "          0.8627, 0.9098, 0.9647, 0.0000],\n",
            "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
            "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
            "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
            "          0.8706, 0.8941, 0.8824, 0.0000],\n",
            "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
            "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
            "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
            "          0.8745, 0.8784, 0.8980, 0.1137],\n",
            "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
            "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
            "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
            "          0.8627, 0.8667, 0.9020, 0.2627],\n",
            "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
            "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
            "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
            "          0.7098, 0.8039, 0.8078, 0.4510],\n",
            "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
            "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
            "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
            "          0.6549, 0.6941, 0.8235, 0.3608],\n",
            "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
            "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
            "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
            "          0.7529, 0.8471, 0.6667, 0.0000],\n",
            "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
            "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
            "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
            "          0.3882, 0.2275, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
            "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEnTq6lmP9Uj",
        "outputId": "2a44d001-78f4-4358-9f5c-661dd071df34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58hNcpRIQCux",
        "outputId": "21d3624f-81f2-4a05-9a28-b2523bd55055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking a sample image and a label"
      ],
      "metadata": {
        "id": "u8_7uEEfQHKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(training_data[0][0][0])\n",
        "# print(training_data[0][1].argmax(1))\n",
        "\n",
        "# plt.title(labels_map[nn.Softmax(dim=1)(training_data[0][1]).argmax(1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "y1NKzRH3QJgD",
        "outputId": "6af724d1-d6b7-4872-e6b8-1366c59c5383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79052c6ccf10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also have to learn a lot about **argmax()**"
      ],
      "metadata": {
        "id": "8WndbVD4T6ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0][0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojcHKJ1gS6ox",
        "outputId": "a3f44597-e0cd-4167-c677-bbbf3b898461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating data loaders for feeding data into the model"
      ],
      "metadata": {
        "id": "SOSGSTLGWcZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_loader=DataLoader(training_data,batch_size=64) #Trying without the shuffle"
      ],
      "metadata": {
        "id": "bjfGEknwWqoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data_loader=DataLoader(test_data,batch_size=64) #Trying without the shuffle"
      ],
      "metadata": {
        "id": "CkKsO4VuW4Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now creating a Linear-Relu Stack with the help of nn"
      ],
      "metadata": {
        "id": "CzleWykiUPEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784,512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512,512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512,10)\n",
        ")"
      ],
      "metadata": {
        "id": "khDEwKcmUTvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now creating a loss function and an optimiser function"
      ],
      "metadata": {
        "id": "XqV19bERU3Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function=nn.CrossEntropyLoss();\n",
        "learning_rate=0.001\n",
        "optimiser=torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "7TjAPbn2U81C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now entering the number of epochs by the user."
      ],
      "metadata": {
        "id": "63r79KZ_VW0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=int(input(\"Enter the number of epochs by the user:\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl_rCg1vVa4C",
        "outputId": "d013b0ba-6575-4611-b6f3-fc7454a2caa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number of epochs by the user:25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now training the model manually with the help of a **training_function()**"
      ],
      "metadata": {
        "id": "iQ0R2G5FVlzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_function(training_data_loader,model,loss_function,optimiser):\n",
        "  model.train()\n",
        "  for batch,(x,y) in enumerate(training_data_loader):\n",
        "\n",
        "    pred_y=model(x) #for predicting the value of y\n",
        "    loss=loss_function(pred_y,y)  #How far the predicted value is from the real value\n",
        "    loss.backward() #backward propagation\n",
        "    optimiser.step()  #Changing the weights\n",
        "    optimiser.zero_grad() #Making the gradient back to zero so it doesnt add up the next time\n",
        "\n",
        "    if (batch%100==0):\n",
        "      print(\"We are at \",(batch*64)+len(x),\"/\",60000)\n",
        "      print(\"loss function value right now:\",loss.item())\n"
      ],
      "metadata": {
        "id": "Gg-qxVd1Vvaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the **testing_function()**"
      ],
      "metadata": {
        "id": "SSgC0C3lZFm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testing_function(testing_data_loader,model,loss_function):\n",
        "  model.eval()\n",
        "  total_loss=0\n",
        "  correct=0\n",
        "  batches=len(testing_data_loader)\n",
        "  with torch.no_grad(): #GOD KNOWS they say its to avoid gradient calculation\n",
        "    for (x,y) in testing_data_loader:\n",
        "      logits=model(x)\n",
        "      correct+=(nn.Softmax(dim=1)(logits).argmax(1)==y.argmax(1)).type(torch.float).sum().item()\n",
        "      total_loss+=loss_function(logits,y).item()\n",
        "\n",
        "\n",
        "  print(\"LOSS:\",total_loss/batches)\n",
        "  print(\"ACCURACY:\",(correct/100))\n"
      ],
      "metadata": {
        "id": "nldDgsKeZQQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally training the model to the data and testing for accuracy at the same time"
      ],
      "metadata": {
        "id": "LGoWiVfyarca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  print(\"---------------------- EPOCH - \",i+1,\" --------------------------\")\n",
        "  training_function(training_data_loader,model,loss_function,optimiser)\n",
        "  testing_function(testing_data_loader,model,loss_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2w9k7-na0EL",
        "outputId": "9c6bf514-b503-4571-a911-860a5e2e64be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------- EPOCH -  1  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.7758098840713501\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.853373646736145\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.6181533336639404\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.8271179795265198\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.7223999500274658\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.7188476920127869\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.8165444135665894\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.78162682056427\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.7981761693954468\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.7519296407699585\n",
            "LOSS: 0.7499158547562399\n",
            "ACCURACY: 72.27\n",
            "---------------------- EPOCH -  2  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.7409875988960266\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.8251534700393677\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.588424563407898\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.8046412467956543\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.7032597064971924\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6962570548057556\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.7929399609565735\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7660239338874817\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.777593731880188\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.7325789928436279\n",
            "LOSS: 0.7290577818253997\n",
            "ACCURACY: 73.4\n",
            "---------------------- EPOCH -  3  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.710314929485321\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.7993939518928528\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.5627315640449524\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.7855113744735718\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6865701675415039\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6773611903190613\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.7711803317070007\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7520301938056946\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.7596525549888611\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.7151011824607849\n",
            "LOSS: 0.7103413518067379\n",
            "ACCURACY: 74.39\n",
            "---------------------- EPOCH -  4  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.6828961372375488\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.7755839824676514\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.5402802228927612\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.7687565088272095\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6718711256980896\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.661214292049408\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.7509047389030457\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7392795085906982\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.7439082264900208\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6990101337432861\n",
            "LOSS: 0.6932775089695196\n",
            "ACCURACY: 75.2\n",
            "---------------------- EPOCH -  5  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.6582608819007874\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.7533844709396362\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.5203956365585327\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.7538044452667236\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6587408185005188\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6471967697143555\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.7317994236946106\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7277395725250244\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.729987621307373\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6840109825134277\n",
            "LOSS: 0.6776375548475108\n",
            "ACCURACY: 76.02\n",
            "---------------------- EPOCH -  6  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.6360780596733093\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.7328233122825623\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.5026717185974121\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.7403714656829834\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6470301747322083\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6350592970848083\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.7138400077819824\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.717372715473175\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.7175992727279663\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6700102686882019\n",
            "LOSS: 0.663264786172065\n",
            "ACCURACY: 76.63\n",
            "---------------------- EPOCH -  7  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.6160989999771118\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.7138069272041321\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.48678067326545715\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.7281394004821777\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6364781856536865\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6244056820869446\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6969736814498901\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7081080079078674\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.7067140936851501\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.656961977481842\n",
            "LOSS: 0.6500450277784068\n",
            "ACCURACY: 77.19\n",
            "---------------------- EPOCH -  8  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5981369018554688\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6962822079658508\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.47247961163520813\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.716945469379425\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6270060539245605\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6150330305099487\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.681157112121582\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.7000299096107483\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6971838474273682\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6446957588195801\n",
            "LOSS: 0.6378841026193777\n",
            "ACCURACY: 77.66\n",
            "---------------------- EPOCH -  9  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5819085836410522\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.68015056848526\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.459581196308136\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.706682562828064\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6184096336364746\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.6067178845405579\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6662890911102295\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6930651664733887\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6888821125030518\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6331611275672913\n",
            "LOSS: 0.6266938345447467\n",
            "ACCURACY: 78.08\n",
            "---------------------- EPOCH -  10  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5671930909156799\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6652555465698242\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.44792506098747253\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6972045302391052\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6106182336807251\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5992403626441956\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6523619294166565\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6871510148048401\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6817238330841064\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6222522258758545\n",
            "LOSS: 0.6163942035596082\n",
            "ACCURACY: 78.55\n",
            "---------------------- EPOCH -  11  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.553782045841217\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.651434063911438\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.4373111128807068\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6884284615516663\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.6034798622131348\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5925029516220093\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6394348740577698\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6822720170021057\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6755607724189758\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6118905544281006\n",
            "LOSS: 0.6069144046610329\n",
            "ACCURACY: 78.75\n",
            "---------------------- EPOCH -  12  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5414903163909912\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6387122869491577\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.4276524782180786\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6803008317947388\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5968893766403198\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.586372971534729\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6273998022079468\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6783133149147034\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6702566146850586\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.6019378304481506\n",
            "LOSS: 0.5981682054935746\n",
            "ACCURACY: 79.15\n",
            "---------------------- EPOCH -  13  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5301100611686707\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6269229650497437\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.41879573464393616\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6726841926574707\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5905952453613281\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5807256102561951\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.616249144077301\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6752437949180603\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6657268404960632\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5924031138420105\n",
            "LOSS: 0.5900858841883908\n",
            "ACCURACY: 79.47\n",
            "---------------------- EPOCH -  14  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5195356011390686\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6159484386444092\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.41063544154167175\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6654610633850098\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5844699740409851\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5754402875900269\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.6059161424636841\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6729311347007751\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6618198156356812\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5831568241119385\n",
            "LOSS: 0.5825954601643192\n",
            "ACCURACY: 79.75\n",
            "---------------------- EPOCH -  15  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5096474289894104\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.6057977080345154\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.40301692485809326\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6585143804550171\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5785351395606995\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5703896284103394\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5963552594184875\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6713266968727112\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6583779454231262\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5741530060768127\n",
            "LOSS: 0.5756390183974224\n",
            "ACCURACY: 80.02\n",
            "---------------------- EPOCH -  16  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.5003126263618469\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5963645577430725\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.3959124684333801\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6518999934196472\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5727051496505737\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5654950737953186\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5874055624008179\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6702601909637451\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6552999019622803\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5654808878898621\n",
            "LOSS: 0.5691680245718379\n",
            "ACCURACY: 80.15\n",
            "---------------------- EPOCH -  17  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4914761185646057\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5875003933906555\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.38934117555618286\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6456012725830078\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5669342875480652\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5607675313949585\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5790438652038574\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6696456074714661\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6525899171829224\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5571398735046387\n",
            "LOSS: 0.563135351345038\n",
            "ACCURACY: 80.41\n",
            "---------------------- EPOCH -  18  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4830835461616516\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.57923823595047\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.383196085691452\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6395280361175537\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5612154603004456\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5561203360557556\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5712488293647766\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6694338917732239\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6501407623291016\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5490764379501343\n",
            "LOSS: 0.5575031072470793\n",
            "ACCURACY: 80.59\n",
            "---------------------- EPOCH -  19  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4750613868236542\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5715388655662537\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.377404123544693\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6336765885353088\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5555460453033447\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5515450239181519\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5639698505401611\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6695011258125305\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6478927135467529\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5413687229156494\n",
            "LOSS: 0.5522397092193555\n",
            "ACCURACY: 80.79\n",
            "---------------------- EPOCH -  20  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4673970639705658\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5643509030342102\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.37189149856567383\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6280876994132996\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5498905181884766\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5469970703125\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5572355389595032\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6697994470596313\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6458330154418945\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5339151620864868\n",
            "LOSS: 0.5473066365263265\n",
            "ACCURACY: 80.88\n",
            "---------------------- EPOCH -  21  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4600769281387329\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5576759576797485\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.36673879623413086\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6226733326911926\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5442749261856079\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5424587726593018\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5509008169174194\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6702015995979309\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6438316702842712\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5266313552856445\n",
            "LOSS: 0.5426775008250194\n",
            "ACCURACY: 80.94\n",
            "---------------------- EPOCH -  22  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.45304635167121887\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5514206886291504\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.3618694841861725\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6174106597900391\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5387426018714905\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5379412770271301\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5449807643890381\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6706943511962891\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.641864001750946\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5195936560630798\n",
            "LOSS: 0.5383291806385015\n",
            "ACCURACY: 81.06\n",
            "---------------------- EPOCH -  23  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.44632241129875183\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5456408262252808\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.3572555184364319\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6123204827308655\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5332772731781006\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5334463715553284\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5394521355628967\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6712274551391602\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6399385929107666\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5128313302993774\n",
            "LOSS: 0.534235410629564\n",
            "ACCURACY: 81.2\n",
            "---------------------- EPOCH -  24  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.43986454606056213\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5402613282203674\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.35291582345962524\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6073781251907349\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.5278680920600891\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5289888978004456\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5342382788658142\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6717967391014099\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.6380455493927002\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5063512921333313\n",
            "LOSS: 0.5303736961191627\n",
            "ACCURACY: 81.29\n",
            "---------------------- EPOCH -  25  --------------------------\n",
            "We are at  64 / 60000\n",
            "loss function value right now: 0.4336748719215393\n",
            "We are at  6464 / 60000\n",
            "loss function value right now: 0.5352303385734558\n",
            "We are at  12864 / 60000\n",
            "loss function value right now: 0.3487926721572876\n",
            "We are at  19264 / 60000\n",
            "loss function value right now: 0.6025892496109009\n",
            "We are at  25664 / 60000\n",
            "loss function value right now: 0.522556722164154\n",
            "We are at  32064 / 60000\n",
            "loss function value right now: 0.5245440006256104\n",
            "We are at  38464 / 60000\n",
            "loss function value right now: 0.5293266773223877\n",
            "We are at  44864 / 60000\n",
            "loss function value right now: 0.6723164916038513\n",
            "We are at  51264 / 60000\n",
            "loss function value right now: 0.636175274848938\n",
            "We are at  57664 / 60000\n",
            "loss function value right now: 0.5001740455627441\n",
            "LOSS: 0.526731935466171\n",
            "ACCURACY: 81.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy** of **71.02%** over 10 epochs"
      ],
      "metadata": {
        "id": "ufIeVmQuA_Hv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy** of **81.49%** over 25 epochs"
      ],
      "metadata": {
        "id": "H93LTLjUH4iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.Softmax(dim=1)(model(training_data[0][0])).argmax(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkJDbb8CcHnb",
        "outputId": "da2da23b-1dc4-4cb1-f9dd-d3f365b3adb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Doubt**:The dimensions are a little confusing,0 means across vertically, and 1 means across horizontally,or so i am guessing"
      ],
      "metadata": {
        "id": "g_8VPbEL_w4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving** the model and its parameters in G-Drive"
      ],
      "metadata": {
        "id": "xzjsaiUQIB5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/SEM_V/NLC/FashionMNIST_model_weights')\n",
        "torch.save(model,'/content/drive/MyDrive/Colab Notebooks/SEM_V/NLC/FashionMNIST_model')"
      ],
      "metadata": {
        "id": "KaX4ntbwIJW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples of **argmax()**"
      ],
      "metadata": {
        "id": "rPR5gM5i_9ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "\n",
        "argmax_axis_0 = torch.argmax(tensor, dim=0) #Here the dimension is 0\n",
        "\n",
        "argmax_axis_1 = torch.argmax(tensor, dim=1) #Here the dimension is 1\n",
        "\n",
        "print(\"Tensor:\")\n",
        "print(tensor)\n",
        "\n",
        "print(\"Argmax along axis 0 (columns):\")\n",
        "print(argmax_axis_0)\n",
        "\n",
        "print(\"Argmax along axis 1 (rows):\")\n",
        "print(argmax_axis_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4enDY-WZACt1",
        "outputId": "6888b201-3d5c-4ce0-9b0f-24d4ce073e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Argmax along axis 0 (columns):\n",
            "tensor([1, 1, 1])\n",
            "Argmax along axis 1 (rows):\n",
            "tensor([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying a few simple experiments with Tensors and shapes"
      ],
      "metadata": {
        "id": "9Mifr4wQAzeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "zeros_tensor = torch.zeros((2, 3))\n",
        "ones_tensor = torch.ones((2, 3))\n",
        "\n",
        "print(\"PyTorch Zeros Tensor:\")\n",
        "print(zeros_tensor)\n",
        "\n",
        "print(\"PyTorch Ones Tensor:\")\n",
        "print(ones_tensor)\n",
        "\n",
        "print(\"Shape of Zeros Tensor:\")\n",
        "print(zeros_tensor.shape)\n",
        "\n",
        "print(\"Shape of Ones Tensor:\")\n",
        "print(ones_tensor.shape)\n",
        "\n",
        "zeros_tensor.add_(ones_tensor)\n",
        "print(\"In-place Addition of Zeros Tensor with Ones Tensor:\")\n",
        "print(zeros_tensor)\n",
        "\n",
        "zeros_tensor.sub_(ones_tensor)\n",
        "print(\"In-place Subtraction of Zeros Tensor with Ones Tensor:\")\n",
        "print(zeros_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr1H2cJbAynC",
        "outputId": "9a33c48f-8ac6-4aa6-ffd8-bc379b70c3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Zeros Tensor:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "PyTorch Ones Tensor:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Shape of Zeros Tensor:\n",
            "torch.Size([2, 3])\n",
            "Shape of Ones Tensor:\n",
            "torch.Size([2, 3])\n",
            "In-place Addition of Zeros Tensor with Ones Tensor:\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "In-place Subtraction of Zeros Tensor with Ones Tensor:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also any operations on tensor would result in a tensor,to extract the values use **item()**"
      ],
      "metadata": {
        "id": "DPhV9Dk7BfCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1=torch.ones((3,2))\n",
        "tensor2=tensor1.sum()\n",
        "print(type(tensor2))\n",
        "print(tensor2)\n",
        "\n",
        "value_of_sum=tensor2.item()\n",
        "print(type(value_of_sum))\n",
        "print(value_of_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lO1Um4mBlRM",
        "outputId": "ac5f539b-b0f3-4884-d7ba-88700279b1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor(6.)\n",
            "<class 'float'>\n",
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things can be converted to or from tensor and numpy"
      ],
      "metadata": {
        "id": "aV8I3cnOCRhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy array to tensor\n",
        "import numpy as np\n",
        "array1=np.ones([2,4])\n",
        "tensor1=torch.from_numpy(array1)\n",
        "print(type(array1))\n",
        "print(type(tensor1))\n",
        "print(tensor1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9cTRJk4CVMK",
        "outputId": "b32a8cee-7f01-4c89-e3a9-e7314ddf35c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor to numpy array\n",
        "import numpy as np\n",
        "tensor1=torch.ones(2,4)\n",
        "array1=tensor1.numpy()\n",
        "print(type(tensor1))\n",
        "print(type(array1))\n",
        "print(array1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW387xa4Co2j",
        "outputId": "479fbe0e-5969-44c1-80ff-afffdc100bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    }
  ]
}