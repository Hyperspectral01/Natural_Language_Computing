{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtsWdPJuPfJK7vrbWa6IaF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyperspectral01/Natural_Language_Computing/blob/main/3.CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is made for learning purposes and is inspired from work at https://www.kaggle.com/code/priyankdl/word2vec-skipgraom-cbow"
      ],
      "metadata": {
        "id": "C81M__1ohgi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CBOW**"
      ],
      "metadata": {
        "id": "o8C1s5ZXhoTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dependencies"
      ],
      "metadata": {
        "id": "KTMB9qWxhrL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1 torchtext==0.15.2\n",
        "!pip install portalocker>=2.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zfXZmGZiyd9",
        "outputId": "574a50a7-2fae-4348-bbcb-5772da7c7fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (71.0.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa5rlkvvhbZl"
      },
      "outputs": [],
      "source": [
        "#For the model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "\n",
        "#For preparing the input to the model\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchtext import datasets\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If cuda is available:"
      ],
      "metadata": {
        "id": "dye6R1aIj4Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  device=torch.device(type='cuda',index=0)\n",
        "else:\n",
        "  device=torch.device(type='cpu',index=0)"
      ],
      "metadata": {
        "id": "AHoSEsehj6-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now taking the IMDB Dataset from torchtext.datasets and playing around with it"
      ],
      "metadata": {
        "id": "Itpnp-DLkQ_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=datasets.IMDB(split='train')"
      ],
      "metadata": {
        "id": "BQe5buMokWjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKvN9PX9kggi",
        "outputId": "e4730b6e-e396-4c7a-fda9-c9197b07b3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So basically you cannot affors to download the entire dataset, so you get a Sharding Filter Iter Data Pipe from the torchtext.datasets and this pipeline then gives you the text you need"
      ],
      "metadata": {
        "id": "tsiS7r7Rk9kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.IMDB(split='test')"
      ],
      "metadata": {
        "id": "HqDHgCBBlN-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_8bDJu_lWad",
        "outputId": "b860cde2-9e36-4d4d-a176-dabbaec5c6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we have two pipelines one for train data and another one for the test data"
      ],
      "metadata": {
        "id": "QRp7Jvb5lZX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use this pipeline to take out the text and store it"
      ],
      "metadata": {
        "id": "6CS9eznklj5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we need only the reviews part of the dataset and not the label or the sentiment part of the dataset, lets go ahead and store it"
      ],
      "metadata": {
        "id": "ELKetD0Ql1DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_reviews=[]\n",
        "for label,review in train_data:\n",
        "  train_reviews.append(review)\n",
        "  if (len(train_reviews)>=1000):\n",
        "    break\n",
        "\n",
        "#train_data is an iterable, sort of a pipeline"
      ],
      "metadata": {
        "id": "ERSSq0GEleQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCtw0FFbmfuR",
        "outputId": "43e90560-02e9-4ddc-95e6-2d5f4ecf8d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3zRuCCQmiyI",
        "outputId": "8b34adcb-62f7-4983-f967-82e28a6d1be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_reviews)) #so basically 25000 review strings for training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS7vVWWommhT",
        "outputId": "a4e56e6c-6b28-4eee-aeb5-555316580a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly for test data"
      ],
      "metadata": {
        "id": "RyFD6t-Sm1Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_reviews=[]\n",
        "for label,review in test_data:\n",
        "  test_reviews.append(review)\n",
        "  if (len(test_reviews)>=1000):\n",
        "    break"
      ],
      "metadata": {
        "id": "4haIs1jAm2-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaEEHYvfnRas",
        "outputId": "89943145-833c-4d0f-a4d6-90062f96612f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_reviews))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEFRMkOTnLdj",
        "outputId": "d4d745b7-8b8c-4c6a-83b6-0cba6921e6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now getting the tokenizer which comes from torchtext.data.utils\n",
        "The advantage here is that once you have your strings you do not need to worry about normalising the text like lowercasing,stemming and lemitization,removing the stopwords,removing the punctuations and so on,tokenizer automatically does all that\n",
        "if (basic_english):_basic_english_normalisation() is called which does that and then the normal split function works"
      ],
      "metadata": {
        "id": "mkjWs-pPn_YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=get_tokenizer(\"basic_english\",language=\"en\")"
      ],
      "metadata": {
        "id": "N7l-ODerokUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we try and proceed in the following manner:\n",
        "\n",
        "input is ready->vocab->dataloader->model->train->test"
      ],
      "metadata": {
        "id": "zSBvgho44o7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the vocab"
      ],
      "metadata": {
        "id": "JOuYMVO5432s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "str1=[\"Hello my name is Shrey Hello\",\"Hello there\"]\n",
        "for token in map(tokenizer,str1):\n",
        "  print(token)\n",
        "\n",
        "print(tokenizer(\"Hello there my name is shrey again!!!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfYJLwBF8Epn",
        "outputId": "88cba057-f70d-4f0f-92a0-d6336614d0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'my', 'name', 'is', 'shrey', 'hello']\n",
            "['hello', 'there']\n",
            "['hello', 'there', 'my', 'name', 'is', 'shrey', 'again', '!', '!', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minimum_allowed_frequency=20\n",
        "\n",
        "list_of_tokens_along_with_duplicates=[]\n",
        "for review in train_reviews:\n",
        "  list_of_tokens_along_with_duplicates.append(tokenizer(review))\n",
        "\n",
        "print(\"The iterable is a list of lists wherein the inner list would be the list of tokens corresponding to that string at that place\")\n",
        "\n",
        "vocab=build_vocab_from_iterator(\n",
        "    list_of_tokens_along_with_duplicates, #map(tokenizer,train_reviews)\n",
        "    min_freq=20,\n",
        "    specials=[\"<unk>\"],\n",
        "    special_first=False\n",
        ")\n",
        "\n",
        "print(type(vocab))\n",
        "\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "print(vocab.lookup_indices([\"<unk>\"]))\n",
        "print(vocab[\"<unk>\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B2SA0GA43BG",
        "outputId": "fae06069-9b34-4078-8edf-680b3a51cf51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The iterable is a list of lists wherein the inner list would be the list of tokens corresponding to that string at that place\n",
            "<class 'torchtext.vocab.vocab.Vocab'>\n",
            "[1198]\n",
            "1198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basically the vocab is of the nature of a dictionary (but it is actually of the type torchtext.vocab.Vocab), where the key is the token string and the value is its index in the vocab"
      ],
      "metadata": {
        "id": "lfEYlYGf_rDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The size of the vocab is \",vocab.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTv91FUEAAG8",
        "outputId": "32b90507-34e1-4815-df4c-96ed2acd4b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the vocab is  1199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a text pipeline"
      ],
      "metadata": {
        "id": "o4BvSi8ZElUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_pipeline(review):\n",
        "  return vocab.lookup_indices(tokenizer(review))"
      ],
      "metadata": {
        "id": "aCIzuKMbEnWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the colate function for the dataloader"
      ],
      "metadata": {
        "id": "KWwGZRzFDfcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size=4\n",
        "context_window_size=9\n",
        "batch_size=16"
      ],
      "metadata": {
        "id": "FpNGI5CoE6kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def colate_function(batch,text_pipeline):\n",
        "  input=[]\n",
        "  ground_truth=[]\n",
        "\n",
        "  for review in batch:\n",
        "    tokens=text_pipeline(review)\n",
        "\n",
        "    if (len(tokens)<context_window_size):\n",
        "      continue\n",
        "    else:\n",
        "      for idx in range(len(tokens)-context_window_size+1):\n",
        "        context_window=tokens[idx:idx+context_window_size]\n",
        "        target=context_window.pop(window_size)\n",
        "        input.append(context_window)\n",
        "        ground_truth.append(target)\n",
        "\n",
        "  input=torch.tensor(input,dtype=torch.long)\n",
        "  ground_truth=torch.tensor(ground_truth,dtype=torch.long)\n",
        "\n",
        "  return input,ground_truth"
      ],
      "metadata": {
        "id": "4rRj7TUoDilM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now using the colate function to create a custom dataloader,\n",
        "dataloaders are used to convert the normal input data types to tensors that can be understood by model,\n",
        "secondly,it is used to create custom dataloaders using colate function"
      ],
      "metadata": {
        "id": "izjtaiVTGnQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader=DataLoader(\n",
        "    train_reviews,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=partial(colate_function,text_pipeline=text_pipeline)\n",
        ")"
      ],
      "metadata": {
        "id": "mOgQ08PKG00T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader=DataLoader(\n",
        "    test_reviews,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=partial(colate_function,text_pipeline=text_pipeline)\n",
        ")"
      ],
      "metadata": {
        "id": "S5xSzh_wHlqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now for the model part"
      ],
      "metadata": {
        "id": "aGhNc6efH1-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.emb1=nn.Embedding(\n",
        "        num_embeddings=vocab_size,\n",
        "        embedding_dim=300,\n",
        "        max_norm=1\n",
        "    )\n",
        "\n",
        "    self.linear1=nn.Linear(\n",
        "        in_features=300,\n",
        "        out_features=vocab_size\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.emb1(x)\n",
        "    x=x.mean(axis=1)\n",
        "    x=self.linear1(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vi_alhNvH3so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally train one epoch and test for accuracy after one epoch"
      ],
      "metadata": {
        "id": "56q8ezxuKZzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model,dataloader,optimiser,loss_function):\n",
        "  model.train()\n",
        "\n",
        "  running_loss=[]\n",
        "  for i,batch_data in enumerate(dataloader):\n",
        "    inputs=batch_data[0].to(device)\n",
        "    target=batch_data[1].to(device)\n",
        "    outputs=model(inputs)\n",
        "    loss=loss_function(outputs,target)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "  print(\"The Loss for this epoch is \",np.mean(running_loss))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tn2Jy9zhKeeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def try_testing_after_one_epoch(model,dataloader,loss_function):\n",
        "  model.eval()\n",
        "\n",
        "  running_losses=[]\n",
        "  for i,batch_data in enumerate(dataloader):\n",
        "    inputs=batch_data[0]\n",
        "    targets=batch_data[1]\n",
        "    outputs=model(inputs)\n",
        "    loss=loss_function(outputs,targets)\n",
        "    running_losses.append(loss.item())\n",
        "\n",
        "  print(\"The Evaluation on testing data after this epoch is \",np.mean(running_losses))"
      ],
      "metadata": {
        "id": "BxkVdDfbOApd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the optimiser and the loss function"
      ],
      "metadata": {
        "id": "90gyAF5cMu46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=CBOW(vocab.__len__()).to(device)\n",
        "\n",
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimiser=optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "B2n2d1UdL56w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now finally the training part for epochs=1"
      ],
      "metadata": {
        "id": "KED-Cfh_NZls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  #Epochs=1\n",
        "  print(\"Epochs number:\",i+1)\n",
        "  train_one_epoch(model,train_dataloader,optimiser,loss_function)\n",
        "  try_testing_after_one_epoch(model,test_dataloader,loss_function)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKwjA6wnNc6e",
        "outputId": "90d07a94-f9cd-4f76-bab0-5956132db615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs number: 1\n",
            "The Loss for this epoch is  6.656619927239796\n",
            "The Evaluation on testing data after this epoch is  5.9288262866792225\n",
            "Epochs number: 2\n",
            "The Loss for this epoch is  5.460186655559237\n",
            "The Evaluation on testing data after this epoch is  5.066986477564251\n",
            "Epochs number: 3\n",
            "The Loss for this epoch is  5.02956541757735\n",
            "The Evaluation on testing data after this epoch is  4.882398423694429\n",
            "Epochs number: 4\n",
            "The Loss for this epoch is  4.955040621379065\n",
            "The Evaluation on testing data after this epoch is  4.84975246399168\n",
            "Epochs number: 5\n",
            "The Loss for this epoch is  4.943546537369016\n",
            "The Evaluation on testing data after this epoch is  4.841776219625322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to trim the model and check the similarities of various word embeddings"
      ],
      "metadata": {
        "id": "uKzs4IqejDdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name,child in model.named_children():\n",
        "    print(name,child)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u8CYgu4jI60",
        "outputId": "2c3385f3-9b0e-4590-97ed-66c27aa56f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb1 Embedding(1199, 300, max_norm=1)\n",
            "linear1 Linear(in_features=300, out_features=1199, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_model=model.emb1\n",
        "print(trimmed_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNSsyk3SjLGb",
        "outputId": "2f4022e4-6a14-41ba-de71-1e5d5c9a3409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(1199, 300, max_norm=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb1=trimmed_model(torch.tensor([vocab.lookup_indices([\"film\"])]).to(device))\n",
        "emb2=trimmed_model(torch.tensor([vocab.lookup_indices([\"movie\"])]).to(device))\n",
        "print(emb1.shape, emb2.shape)\n",
        "cos=torch.nn.CosineSimilarity(dim=2)\n",
        "print(cos(emb1,emb2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zKx5MexjT6T",
        "outputId": "c98a9b4d-9b12-4248-b2f5-92256aa99323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 300]) torch.Size([1, 1, 300])\n",
            "tensor([[0.9924]], grad_fn=<SumBackward1>)\n"
          ]
        }
      ]
    }
  ]
}